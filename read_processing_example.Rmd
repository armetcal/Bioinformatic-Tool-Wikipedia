---
title: Raw Read Processing Example 
output:
  html_document:
    #css: "../css/styles.css"
    toc: true     
    toc_depth: 3     
    toc_float:       
      collapsed: false       
      smooth_scroll: false 
---

# Background

Now that we've gone through each step individually, we will put all of the steps
together and process two paired-end samples. We will assume that all
installations and downloads other than our reads are complete.

We will download two random samples from Wallen et. al's 2022 paper,
"Metagenomics of Parkinsonâ€™s disease implicates the gut microbiome in multiple
disease mechanisms".

The steps covered will include:

1.  Download reads from two samples
2.  Check the initial quality using FastQC
3.  Trim and filter reads for quality
4.  Remove human reads
5.  Check the final quality using FastQC

# Step 1: Download Reads

Note that the project accession is PRJNA834801, but we will only download two
reads for this example. It took 41 minutes to download a total of 3.7 GB -
ensure that your computer does not disconnect from the server while the code is
running. We can't submit a job since the computational nodes don't have internet
access.

## 1a. Run Code

```{bash, eval=FALSE, warning=FALSE, include=T, results='hide'}
# This will be our working directory
mkdir scratch/test_pipe2
# This is where raw sequences will be downloaded
mkdir scratch/test_pipe2/sequences
# Go to the sequences directory
cd scratch/test_pipe2/sequences

# Accession
project="PRJNA834801"

# Load the SRA Toolkit
module load sra-toolkit/3.0.9

# Make a list of all fastq files associated with the project, save the file accessions to a list (SRR.numbers), and download them.
# -j 2 means 2 processes at a time.
# IF YOU ARE RUNNING THIS IN A LOGIN NODE, DO NOT INCREASE J. If you're submitting it to a computational node, you can remove the "-j 2".
esearch -db sra -query $project | efetch -format runinfo > runinfo.csv
cat runinfo.csv | cut -d "," -f 1 > SRR.numbers

# Select first three lines (2 samples) ~~~~~~~~~~~~~~~~~
# Note: overwriting doesn't work.
head -n 3 SRR.numbers > SRR.numbers.2
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# Download reads
cat SRR.numbers.2 | parallel -j 2 fastq-dump --split-files --origfmt --gzip {}
```

## 1b. Outputs

The following code is printed to the console. First there were several error
messages, which is an artifact of the way SRR.numbers.2 is formatted; however,
the code then runs normally for the two samples.

![](images/clipboard-2528279973.png){width="322"}

Inspecting our sequences folder using ls -l \*, we see that four fastq.gz files
have been downloaded, with each one being 1.2-1.6 GB. (Because the reads are
split into forward/reverse when downloaded, the combined size is larger than the
actual download.)

![](images/clipboard-2677985302.png){width="457"}

# Step 2: Check Quality

## 2a. Run Code

First we return to our project directory, then open a new script:

```{bash, eval=FALSE, warning=FALSE, include=T, results='hide'}
# Return to the project main folder
cd ..
# Make the new folder and initialize a script
nano run_fastqc.sh
```

In the script, paste the following and then hit Ctrl+S and Ctrl+X to save and
exit. Note that the time is designed for only four read files (two samples).

```{bash, eval=FALSE, warning=FALSE, include=T, results='hide'}
#!/bin/bash

#SBATCH --account=def-bfinlay   # Change bfinlay to your professor's username
#SBATCH --time=01:00:00      # Adjust time as needed
#SBATCH --cpus-per-task=10
#SBATCH --mem=15G 

# Make the folder that will store all fastqc outputs
# This folder will also be used when we run fastqc at the end.
mkdir fastqc_out

# Load FastQC and its dependencies - update versions as needed.
module load StdEnv/2023 fastqc/0.12.1
# Run FastQC on all forward read files
parallel fastqc --outdir=fastqc_out ::: sequences/*.fastq.gz
```

Then run the script using `sbatch run_fastqc.sh`.

## 2b. Outputs

# Step 3: Trim and Filter

## 3a. Run Code

Start a new script by writing `nano run_bbduk.sh`. In the script, paste the
following and then hit Ctrl+S and Ctrl+X to save and exit. Note that the time is
designed for only four read files (two samples).

```{bash, eval=FALSE, warning=FALSE, include=T, results='hide'}
#!/bin/bash

#SBATCH --account=def-bfinlay   # Change bfinlay to your professor's username
#SBATCH --time=01:00:00      # Adjust time as needed
#SBATCH --cpus-per-task=10
#SBATCH --mem=15G 

# Load the dependencies
module load StdEnv/2023 bbmap/39.06 java/21.0.1

# Make the output directories
mkdir bbduk_out
mkdir bbduk_out/stats

# Trim and filter, all in one step
bbduk.sh \
 in=path/to/fwd/reads/file_1.fastq.gz \
 in2=path/to/rev/reads/file_2.fastq.gz \
 out=bbduk_out/file_1.fastq.gz \
 out2=bbduk_out/file_2.fastq.gz \
 outm=bbduk_out/file_removed.fastq.gz \
 stats=bbduk_out/stats/file_stats.txt \
 tpe tbo qtrim=rl trimq=25 maq=25 minlen=50 ref=adapters,phix \
 -Xmx15g
```
